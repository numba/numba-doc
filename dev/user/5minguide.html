<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>1.1. A ~5 minute guide to Numba &#8212; Numba 0.47.0.dev0+476.g50a00b1-py3.7-linux-x86_64.egg documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/numba-docs.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1.2. Overview" href="overview.html" />
    <link rel="prev" title="1. User Manual" href="index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/numba_blue_icon_rgb.png"></span>
          Numba</a>
        <span class="navbar-text navbar-version pull-left"><b>0.47</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">1. User Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">2. Reference Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/index.html">3. Numba for CUDA GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda-reference/index.html">4. CUDA Python Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../roc/index.html">5. Numba for AMD ROC GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extending/index.html">6. Extending Numba</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/index.html">7. Developer Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../proposals/index.html">8. Numba Enhancement Proposals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">9. Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release-notes.html">10. Release Notes</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">1.1. A ~5 minute guide to Numba</a><ul>
<li><a class="reference internal" href="#how-do-i-get-it">1.1.1. How do I get it?</a></li>
<li><a class="reference internal" href="#will-numba-work-for-my-code">1.1.2. Will Numba work for my code?</a></li>
<li><a class="reference internal" href="#what-is-nopython-mode">1.1.3. What is <code class="docutils literal notranslate"><span class="pre">nopython</span></code> mode?</a></li>
<li><a class="reference internal" href="#how-to-measure-the-performance-of-numba">1.1.4. How to measure the performance of Numba?</a></li>
<li><a class="reference internal" href="#how-fast-is-it">1.1.5. How fast is it?</a></li>
<li><a class="reference internal" href="#how-does-numba-work">1.1.6. How does Numba work?</a></li>
<li><a class="reference internal" href="#other-things-of-interest">1.1.7. Other things of interest:</a><ul>
<li><a class="reference internal" href="#gpu-targets">1.1.7.1. GPU targets:</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="index.html" title="Previous Chapter: 1. User Manual"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; 1. User Manual</span>
    </a>
  </li>
  <li>
    <a href="overview.html" title="Next Chapter: 1.2. Overview"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">1.2. Overview &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/user/5minguide.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="a-5-minute-guide-to-numba">
<span id="numba-5-mins"></span><h1>1.1. A ~5 minute guide to Numba<a class="headerlink" href="#a-5-minute-guide-to-numba" title="Permalink to this headline">¶</a></h1>
<p>Numba is a just-in-time compiler for Python that works best on code that uses
NumPy arrays and functions, and loops. The most common way to use Numba is
through its collection of decorators that can be applied to your functions to
instruct Numba to compile them. When a call is made to a Numba decorated
function it is compiled to machine code “just-in-time” for execution and all or
part of your code can subsequently run at native machine code speed!</p>
<p>Out of the box Numba works with the following:</p>
<ul class="simple">
<li>OS: Windows (32 and 64 bit), OSX and Linux (32 and 64 bit)</li>
<li>Architecture: x86, x86_64, ppc64le. Experimental on armv7l, armv8l (aarch64).</li>
<li>GPUs: Nvidia CUDA. Experimental on AMD ROC.</li>
<li>CPython</li>
<li>NumPy 1.10 - latest</li>
</ul>
<div class="section" id="how-do-i-get-it">
<h2>1.1.1. How do I get it?<a class="headerlink" href="#how-do-i-get-it" title="Permalink to this headline">¶</a></h2>
<p>Numba is available as a <a class="reference external" href="https://conda.io/docs/">conda</a> package for the
<a class="reference external" href="https://www.anaconda.com/">Anaconda Python distribution</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ conda install numba
</pre></div>
</div>
<p>Numba also has wheels available:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pip install numba
</pre></div>
</div>
<p>Numba can also be
<a class="reference internal" href="installing.html#numba-source-install-instructions"><span class="std std-ref">compiled from source</span></a>, although we do
not recommend it for first-time Numba users.</p>
<p>Numba is often used as a core package so its dependencies are kept to an
absolute minimum, however, extra packages can be installed as follows to provide
additional functionality:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">scipy</span></code> - enables support for compiling <code class="docutils literal notranslate"><span class="pre">numpy.linalg</span></code> functions.</li>
<li><code class="docutils literal notranslate"><span class="pre">colorama</span></code> - enables support for color highlighting in backtraces/error
messages.</li>
<li><code class="docutils literal notranslate"><span class="pre">pyyaml</span></code> - enables configuration of Numba via a YAML config file.</li>
<li><code class="docutils literal notranslate"><span class="pre">icc_rt</span></code> - allows the use of the Intel SVML (high performance short vector
math library, x86_64 only). Installation instructions are in the
<a class="reference internal" href="performance-tips.html#intel-svml"><span class="std std-ref">performance tips</span></a>.</li>
</ul>
</div>
<div class="section" id="will-numba-work-for-my-code">
<h2>1.1.2. Will Numba work for my code?<a class="headerlink" href="#will-numba-work-for-my-code" title="Permalink to this headline">¶</a></h2>
<p>This depends on what your code looks like, if your code is numerically
orientated (does a lot of math), uses NumPy a lot and/or has a lot of loops,
then Numba is often a good choice. In these examples we’ll apply the most
fundamental of Numba’s JIT decorators, <code class="docutils literal notranslate"><span class="pre">&#64;jit</span></code>, to try and speed up some
functions to demonstrate what works well and what does not.</p>
<p>Numba works well on code that looks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numba</span> <span class="k">import</span> <span class="n">jit</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="nd">@jit</span><span class="p">(</span><span class="n">nopython</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># Set &quot;nopython&quot; mode for best performance, equivalent to @njit</span>
<span class="k">def</span> <span class="nf">go_fast</span><span class="p">(</span><span class="n">a</span><span class="p">):</span> <span class="c1"># Function is compiled to machine code when called the first time</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>   <span class="c1"># Numba likes loops</span>
        <span class="n">trace</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span> <span class="c1"># Numba likes NumPy functions</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">trace</span>              <span class="c1"># Numba likes NumPy broadcasting</span>

<span class="nb">print</span><span class="p">(</span><span class="n">go_fast</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>It won’t work very well, if at all, on code that looks like this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numba</span> <span class="k">import</span> <span class="n">jit</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;a&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="s1">&#39;b&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">]}</span>

<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">use_pandas</span><span class="p">(</span><span class="n">a</span><span class="p">):</span> <span class="c1"># Function will not benefit from Numba jit</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">a</span><span class="p">)</span> <span class="c1"># Numba doesn&#39;t know about pd.DataFrame</span>
    <span class="n">df</span> <span class="o">+=</span> <span class="mi">1</span>                        <span class="c1"># Numba doesn&#39;t understand what this is</span>
    <span class="k">return</span> <span class="n">df</span><span class="o">.</span><span class="n">cov</span><span class="p">()</span>                <span class="c1"># or this!</span>

<span class="nb">print</span><span class="p">(</span><span class="n">use_pandas</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>Note that Pandas is not understood by Numba and as a result Numba would simply
run this code via the interpreter but with the added cost of the Numba internal
overheads!</p>
</div>
<div class="section" id="what-is-nopython-mode">
<h2>1.1.3. What is <code class="docutils literal notranslate"><span class="pre">nopython</span></code> mode?<a class="headerlink" href="#what-is-nopython-mode" title="Permalink to this headline">¶</a></h2>
<p>The Numba <code class="docutils literal notranslate"><span class="pre">&#64;jit</span></code> decorator fundamentally operates in two compilation modes,
<code class="docutils literal notranslate"><span class="pre">nopython</span></code> mode and <code class="docutils literal notranslate"><span class="pre">object</span></code> mode. In the <code class="docutils literal notranslate"><span class="pre">go_fast</span></code> example above,
<code class="docutils literal notranslate"><span class="pre">nopython=True</span></code> is set in the <code class="docutils literal notranslate"><span class="pre">&#64;jit</span></code> decorator, this is instructing Numba to
operate in <code class="docutils literal notranslate"><span class="pre">nopython</span></code> mode. The behaviour of the <code class="docutils literal notranslate"><span class="pre">nopython</span></code> compilation mode
is to essentially compile the decorated function so that it will run entirely
without the involvement of the Python interpreter. This is the recommended and
best-practice way to use the Numba <code class="docutils literal notranslate"><span class="pre">jit</span></code> decorator as it leads to the best
performance.</p>
<p>Should the compilation in <code class="docutils literal notranslate"><span class="pre">nopython</span></code> mode fail, Numba can compile using
<code class="docutils literal notranslate"><span class="pre">object</span> <span class="pre">mode</span></code>, this is a fall back mode for the <code class="docutils literal notranslate"><span class="pre">&#64;jit</span></code> decorator if
<code class="docutils literal notranslate"><span class="pre">nopython=True</span></code> is not set (as seen in the <code class="docutils literal notranslate"><span class="pre">use_pandas</span></code> example above). In
this mode Numba will identify loops that it can compile and compile those into
functions that run in machine code, and it will run the rest of the code in the
interpreter. For best performance avoid using this mode!</p>
</div>
<div class="section" id="how-to-measure-the-performance-of-numba">
<h2>1.1.4. How to measure the performance of Numba?<a class="headerlink" href="#how-to-measure-the-performance-of-numba" title="Permalink to this headline">¶</a></h2>
<p>First, recall that Numba has to compile your function for the argument types
given before it executes the machine code version of your function, this takes
time. However, once the compilation has taken place Numba caches the machine
code version of your function for the particular types of arguments presented.
If it is called again the with same types, it can reuse the cached version
instead of having to compile again.</p>
<p>A really common mistake when measuring performance is to not account for the
above behaviour and to time code once with a simple timer that includes the
time taken to compile your function in the execution time.</p>
<p>For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numba</span> <span class="k">import</span> <span class="n">jit</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="nd">@jit</span><span class="p">(</span><span class="n">nopython</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">go_fast</span><span class="p">(</span><span class="n">a</span><span class="p">):</span> <span class="c1"># Function is compiled and runs in machine code</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="n">trace</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">a</span> <span class="o">+</span> <span class="n">trace</span>

<span class="c1"># DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">go_fast</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Elapsed (with compilation) = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>

<span class="c1"># NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">go_fast</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Elapsed (after compilation) = </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">))</span>
</pre></div>
</div>
<p>This, for example prints:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Elapsed</span> <span class="p">(</span><span class="k">with</span> <span class="n">compilation</span><span class="p">)</span> <span class="o">=</span> <span class="mf">0.33030009269714355</span>
<span class="n">Elapsed</span> <span class="p">(</span><span class="n">after</span> <span class="n">compilation</span><span class="p">)</span> <span class="o">=</span> <span class="mf">6.67572021484375e-06</span>
</pre></div>
</div>
<p>A good way to measure the impact Numba JIT has on your code is to time execution
using the <a class="reference external" href="https://docs.python.org/3/library/timeit.html">timeit</a> module
functions, these measure multiple iterations of execution and, as a result,
can be made to accommodate for the compilation time in the first execution.</p>
<p>As a side note, if compilation time is an issue, Numba JIT supports
<a class="reference internal" href="../reference/jit-compilation.html#jit-decorator-cache"><span class="std std-ref">on-disk caching</span></a> of compiled functions and also has
an <a class="reference internal" href="../reference/aot-compilation.html#aot-compilation"><span class="std std-ref">Ahead-Of-Time</span></a> compilation mode.</p>
</div>
<div class="section" id="how-fast-is-it">
<h2>1.1.5. How fast is it?<a class="headerlink" href="#how-fast-is-it" title="Permalink to this headline">¶</a></h2>
<p>Assuming Numba can operate in <code class="docutils literal notranslate"><span class="pre">nopython</span></code> mode, or at least compile some loops,
it will target compilation to your specific CPU. Speed up varies depending on
application but can be one to two orders of magnitude. Numba has a
<a class="reference internal" href="performance-tips.html#performance-tips"><span class="std std-ref">performance guide</span></a> that covers common options for
gaining extra performance.</p>
</div>
<div class="section" id="how-does-numba-work">
<h2>1.1.6. How does Numba work?<a class="headerlink" href="#how-does-numba-work" title="Permalink to this headline">¶</a></h2>
<p>Numba reads the Python bytecode for a decorated function and combines this with
information about the types of the input arguments to the function. It analyzes
and optimizes your code, and finally uses the LLVM compiler library to generate
a machine code version of your function, tailored to your CPU capabilities. This
compiled version is then used every time your function is called.</p>
</div>
<div class="section" id="other-things-of-interest">
<h2>1.1.7. Other things of interest:<a class="headerlink" href="#other-things-of-interest" title="Permalink to this headline">¶</a></h2>
<p>Numba has quite a few decorators, we’ve seen <code class="docutils literal notranslate"><span class="pre">&#64;jit</span></code>, but there’s
also:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">&#64;njit</span></code> - this is an alias for <code class="docutils literal notranslate"><span class="pre">&#64;jit(nopython=True)</span></code> as it is so commonly
used!</li>
<li><code class="docutils literal notranslate"><span class="pre">&#64;vectorize</span></code> - produces NumPy <code class="docutils literal notranslate"><span class="pre">ufunc</span></code> s (with all the <code class="docutils literal notranslate"><span class="pre">ufunc</span></code> methods
supported). <a class="reference internal" href="vectorize.html#vectorize"><span class="std std-ref">Docs are here</span></a>.</li>
<li><code class="docutils literal notranslate"><span class="pre">&#64;guvectorize</span></code> - produces NumPy generalized <code class="docutils literal notranslate"><span class="pre">ufunc</span></code> s.
<a class="reference internal" href="vectorize.html#guvectorize"><span class="std std-ref">Docs are here</span></a>.</li>
<li><code class="docutils literal notranslate"><span class="pre">&#64;stencil</span></code> - declare a function as a kernel for a stencil like operation.
<a class="reference internal" href="stencil.html#numba-stencil"><span class="std std-ref">Docs are here</span></a>.</li>
<li><code class="docutils literal notranslate"><span class="pre">&#64;jitclass</span></code> - for jit aware classes. <a class="reference internal" href="jitclass.html#jitclass"><span class="std std-ref">Docs are here</span></a>.</li>
<li><code class="docutils literal notranslate"><span class="pre">&#64;cfunc</span></code> - declare a function for use as a native call back (to be called
from C/C++ etc). <a class="reference internal" href="cfunc.html#cfunc"><span class="std std-ref">Docs are here</span></a>.</li>
<li><code class="docutils literal notranslate"><span class="pre">&#64;overload</span></code> - register your own implementation of a function for use in
nopython mode, e.g. <code class="docutils literal notranslate"><span class="pre">&#64;overload(scipy.special.j0)</span></code>.
<a class="reference internal" href="../extending/high-level.html#high-level-extending"><span class="std std-ref">Docs are here</span></a>.</li>
</ul>
<p>Extra options available in some decorators:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">parallel</span> <span class="pre">=</span> <span class="pre">True</span></code> - <a class="reference internal" href="../reference/jit-compilation.html#jit-decorator-parallel"><span class="std std-ref">enable</span></a> the
<a class="reference internal" href="parallel.html#numba-parallel"><span class="std std-ref">automatic parallelization</span></a> of the function.</li>
<li><code class="docutils literal notranslate"><span class="pre">fastmath</span> <span class="pre">=</span> <span class="pre">True</span></code> - enable <a class="reference internal" href="../reference/jit-compilation.html#jit-decorator-fastmath"><span class="std std-ref">fast-math</span></a>
behaviour for the function.</li>
</ul>
<p>ctypes/cffi/cython interoperability:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">cffi</span></code> - The calling of <a class="reference internal" href="../reference/pysupported.html#cffi-support"><span class="std std-ref">CFFI</span></a> functions is supported
in <code class="docutils literal notranslate"><span class="pre">nopython</span></code> mode.</li>
<li><code class="docutils literal notranslate"><span class="pre">ctypes</span></code> - The calling of <a class="reference internal" href="../reference/pysupported.html#ctypes-support"><span class="std std-ref">ctypes</span></a> wrapped
functions is supported in <code class="docutils literal notranslate"><span class="pre">nopython</span></code> mode.
.</li>
<li>Cython exported functions <a class="reference internal" href="../extending/high-level.html#cython-support"><span class="std std-ref">are callable</span></a>.</li>
</ul>
<div class="section" id="gpu-targets">
<h3>1.1.7.1. GPU targets:<a class="headerlink" href="#gpu-targets" title="Permalink to this headline">¶</a></h3>
<p>Numba can target <a class="reference external" href="https://developer.nvidia.com/cuda-zone">Nvidia CUDA</a> and
(experimentally) <a class="reference external" href="https://rocm.github.io/">AMD ROC</a> GPUs. You can write a
kernel in pure Python and have Numba handle the computation and data movement
(or do this explicitly). Click for Numba documentation on
<a class="reference internal" href="../cuda/index.html#cuda-index"><span class="std std-ref">CUDA</span></a> or <a class="reference internal" href="../roc/index.html#roc-index"><span class="std std-ref">ROC</span></a>.</p>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2012, Anaconda, Inc..<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>