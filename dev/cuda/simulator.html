<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>3.11. Debugging CUDA Python with the the CUDA Simulator &mdash; Numba 0.43.0.dev0+213.g8cbe10b-py2.7-linux-x86_64.egg documentation</title>
    
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/numba-docs.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.43.0.dev0+213.g8cbe10b-py2.7-linux-x86_64.egg',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="Numba 0.43.0.dev0+213.g8cbe10b-py2.7-linux-x86_64.egg documentation" href="../index.html" />
    <link rel="up" title="3. Numba for CUDA GPUs" href="index.html" />
    <link rel="next" title="3.12. GPU Reduction" href="reduction.html" />
    <link rel="prev" title="3.10. Examples" href="examples.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/numba_blue_icon_rgb.png"></span>
          Numba</a>
        <span class="navbar-text navbar-version pull-left"><b>0.43</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../user/index.html">1. User Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">2. Reference Manual</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">3. Numba for CUDA GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda-reference/index.html">4. CUDA Python Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../roc/index.html">5. Numba for AMD ROC GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extending/index.html">6. Extending Numba</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/index.html">7. Developer Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../proposals/index.html">8. Numba Enhancement Proposals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">9. Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release-notes.html">10. Release Notes</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">3.11. Debugging CUDA Python with the the CUDA Simulator</a><ul>
<li><a class="reference internal" href="#using-the-simulator">3.11.1. Using the simulator</a></li>
<li><a class="reference internal" href="#supported-features">3.11.2. Supported features</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="examples.html" title="Previous Chapter: 3.10. Examples"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; 3.10. Examples</span>
    </a>
  </li>
  <li>
    <a href="reduction.html" title="Next Chapter: 3.12. GPU Reduction"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">3.12. GPU Reduct... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/cuda/simulator.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="debugging-cuda-python-with-the-the-cuda-simulator">
<span id="simulator"></span><h1>3.11. Debugging CUDA Python with the the CUDA Simulator<a class="headerlink" href="#debugging-cuda-python-with-the-the-cuda-simulator" title="Permalink to this headline">¶</a></h1>
<p>Numba includes a CUDA Simulator that implements most of the semantics in CUDA
Python using the Python interpreter and some additional Python code. This can
be used to debug CUDA Python code, either by adding print statements to your
code, or by using the debugger to step through the execution of an individual
thread.</p>
<p>Execution of kernels is performed by the simulator one block at a time. One
thread is spawned for each thread in the block, and scheduling of the execution
of these threads is left up to the operating system.</p>
<div class="section" id="using-the-simulator">
<h2>3.11.1. Using the simulator<a class="headerlink" href="#using-the-simulator" title="Permalink to this headline">¶</a></h2>
<p>The simulator is enabled by setting the environment variable
<span class="target" id="index-0"></span><a class="reference internal" href="../reference/envvars.html#envvar-NUMBA_ENABLE_CUDASIM"><code class="xref std std-envvar docutils literal"><span class="pre">NUMBA_ENABLE_CUDASIM</span></code></a> to 1. CUDA Python code may then be executed as
normal. The easiest way to use the debugger inside a kernel is to only stop a
single thread, otherwise the interaction with the debugger is difficult to
handle. For example, the kernel below will  stop in the thread <code class="docutils literal"><span class="pre">&lt;&lt;&lt;(3,0,0),</span> <span class="pre">(1,</span>
<span class="pre">0,</span> <span class="pre">0)&gt;&gt;&gt;</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="nd">@cuda.jit</span>
<span class="k">def</span> <span class="nf">vec_add</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">out</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
    <span class="n">bx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span>
    <span class="n">bdx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">bx</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">pdb</span> <span class="kn">import</span> <span class="n">set_trace</span><span class="p">;</span> <span class="n">set_trace</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">bx</span> <span class="o">*</span> <span class="n">bdx</span> <span class="o">+</span> <span class="n">x</span>
    <span class="n">out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">B</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>
<p>when invoked with a one-dimensional grid and one-dimensional blocks.</p>
</div>
<div class="section" id="supported-features">
<h2>3.11.2. Supported features<a class="headerlink" href="#supported-features" title="Permalink to this headline">¶</a></h2>
<p>The simulator aims to provide as complete a simulation of execution on a real
GPU as possible - in particular, the following are supported:</p>
<ul class="simple">
<li>Atomic operations</li>
<li>Constant memory</li>
<li>Local memory</li>
<li>Shared memory: declarations of shared memory arrays must be on separate source
lines, since the simulator uses source line information to keep track of
allocations of shared memory across threads.</li>
<li><a class="reference internal" href="../cuda-reference/kernel.html#numba.cuda.syncthreads" title="numba.cuda.syncthreads"><code class="xref py py-func docutils literal"><span class="pre">syncthreads()</span></code></a> is supported - however, in the case where divergent
threads enter different <a class="reference internal" href="../cuda-reference/kernel.html#numba.cuda.syncthreads" title="numba.cuda.syncthreads"><code class="xref py py-func docutils literal"><span class="pre">syncthreads()</span></code></a> calls, the launch will not fail,
but unexpected behaviour will occur. A future version of the simulator may
detect this condition.</li>
<li>The stream API is supported, but all operations occur sequentially and
synchronously, unlike on a real device. Synchronising on a stream is therefore
a no-op.</li>
<li>The event API is also supported, but provides no meaningful timing
information.</li>
<li>Data transfer to and from the GPU - in particular, creating array objects with
<a class="reference internal" href="../cuda-reference/memory.html#numba.cuda.device_array" title="numba.cuda.device_array"><code class="xref py py-func docutils literal"><span class="pre">device_array()</span></code></a> and <a class="reference internal" href="../cuda-reference/memory.html#numba.cuda.device_array_like" title="numba.cuda.device_array_like"><code class="xref py py-func docutils literal"><span class="pre">device_array_like()</span></code></a>. The APIs for pinned memory
<a class="reference internal" href="../cuda-reference/memory.html#numba.cuda.pinned" title="numba.cuda.pinned"><code class="xref py py-func docutils literal"><span class="pre">pinned()</span></code></a> and <a class="reference internal" href="../cuda-reference/memory.html#numba.cuda.pinned_array" title="numba.cuda.pinned_array"><code class="xref py py-func docutils literal"><span class="pre">pinned_array()</span></code></a> are also supported, but no pinning
takes place.</li>
<li>The driver API implementation of the list of GPU contexts (<code class="docutils literal"><span class="pre">cuda.gpus</span></code> and
<code class="docutils literal"><span class="pre">cuda.cudadrv.devices.gpus</span></code>) is supported, and reports a single GPU context.
This context can be closed and reset as the real one would.</li>
<li>The <a class="reference internal" href="../cuda-reference/host.html#numba.cuda.detect" title="numba.cuda.detect"><code class="xref py py-func docutils literal"><span class="pre">detect()</span></code></a> function is supported, and reports one device called
<cite>SIMULATOR</cite>.</li>
</ul>
<p>Some limitations of the simulator include:</p>
<ul class="simple">
<li>It does not perform type checking/type inference. If any argument types to a
jitted function are incorrect, or if the specification of the type of any
local variables are incorrect, this will not be detected by the simulator.</li>
<li>Only one GPU is simulated.</li>
<li>Multithreaded accesses to a single GPU are not supported, and will result in
unexpected behaviour.</li>
<li>Most of the driver API is unimplemented.</li>
<li>It is not possible to link PTX code with CUDA Python functions.</li>
<li>Warps and warp-level operations are not yet implemented.</li>
</ul>
<p>Obviously, the speed of the simulator is also much lower than that of a real
device. It may be necessary to reduce the size of input data and the size of the
CUDA grid in order to make debugging with the simulator tractable.</p>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2012, Anaconda, Inc..<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>