<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>8.1.2. NBEP 7: CUDA External Memory Management Plugins &#8212; Numba 0.49.0.dev0+919.gafd5c67-py3.7-linux-x86_64.egg documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/numba-docs.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="8.2.1. NBEP 2: Extension points" href="extension-points.html" />
    <link rel="prev" title="8.1.1. NBEP 1: Changes in integer typing" href="integer-typing.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/numba_blue_icon_rgb.png"></span>
          Numba</a>
        <span class="navbar-text navbar-version pull-left"><b>0.49</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../user/index.html">1. User Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">2. Reference Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/index.html">3. Numba for CUDA GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda-reference/index.html">4. CUDA Python Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../roc/index.html">5. Numba for AMD ROC GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extending/index.html">6. Extending Numba</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/index.html">7. Developer Manual</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">8. Numba Enhancement Proposals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">9. Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release-notes.html">10. Release Notes</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">8.1.2. NBEP 7: CUDA External Memory Management Plugins</a><ul>
<li><a class="reference internal" href="#background-and-goals">8.1.2.1. Background and goals</a></li>
<li><a class="reference internal" href="#requirements">8.1.2.2. Requirements</a><ul>
<li><a class="reference internal" href="#device-vs-host-memory">8.1.2.2.1. Device vs. Host memory</a></li>
<li><a class="reference internal" href="#deallocation-strategies">8.1.2.2.2. Deallocation strategies</a></li>
<li><a class="reference internal" href="#management-of-other-objects">8.1.2.2.3. Management of other objects</a></li>
<li><a class="reference internal" href="#asynchronous-allocation-deallocation">8.1.2.2.4. Asynchronous allocation / deallocation</a></li>
<li><a class="reference internal" href="#non-requirements">8.1.2.2.5. Non-requirements</a></li>
</ul>
</li>
<li><a class="reference internal" href="#interface-for-plugin-developers">8.1.2.3. Interface for Plugin developers</a><ul>
<li><a class="reference internal" href="#plugin-base-classes">8.1.2.3.1. Plugin Base Classes</a></li>
<li><a class="reference internal" href="#representing-pointers">8.1.2.3.2. Representing pointers</a><ul>
<li><a class="reference internal" href="#device-memory">8.1.2.3.2.1. Device Memory</a></li>
<li><a class="reference internal" href="#host-memory">8.1.2.3.2.2. Host Memory</a></li>
</ul>
</li>
<li><a class="reference internal" href="#providing-device-memory-management-only">8.1.2.3.3. Providing device memory management only</a></li>
<li><a class="reference internal" href="#import-order">8.1.2.3.4. Import order</a></li>
<li><a class="reference internal" href="#numba-as-a-dependency">8.1.2.3.5. Numba as a Dependency</a></li>
</ul>
</li>
<li><a class="reference internal" href="#example-implementation-a-rapids-memory-manager-rmm-plugin">8.1.2.4. Example implementation - A RAPIDS Memory Manager (RMM) Plugin</a><ul>
<li><a class="reference internal" href="#example-usage">8.1.2.4.1. Example usage</a><ul>
<li><a class="reference internal" href="#setting-the-memory-manager-through-the-environment">8.1.2.4.1.1. Setting the memory manager through the environment</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#numba-internal-changes">8.1.2.5. Numba internal changes</a><ul>
<li><a class="reference internal" href="#current-model-implementation">8.1.2.5.1. Current model / implementation</a></li>
<li><a class="reference internal" href="#proposed-changes">8.1.2.5.2. Proposed changes</a><ul>
<li><a class="reference internal" href="#context-changes">8.1.2.5.2.1. Context changes</a></li>
<li><a class="reference internal" href="#new-components-of-the-driver-module">8.1.2.5.2.2. New components of the <code class="docutils literal notranslate"><span class="pre">driver</span></code> module</a></li>
<li><a class="reference internal" href="#staged-ipc">8.1.2.5.2.3. Staged IPC</a></li>
<li><a class="reference internal" href="#testing">8.1.2.5.2.4. Testing</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#prototyping-experimental-implementation">8.1.2.6. Prototyping / experimental implementation</a><ul>
<li><a class="reference internal" href="#current-implementation-status">8.1.2.6.1. Current implementation status</a><ul>
<li><a class="reference internal" href="#rmm-plugin">8.1.2.6.1.1. RMM Plugin</a></li>
<li><a class="reference internal" href="#cupy-plugin">8.1.2.6.1.2. CuPy Plugin</a></li>
</ul>
</li>
<li><a class="reference internal" href="#numba-cuda-unit-tests">8.1.2.6.2. Numba CUDA Unit tests</a><ul>
<li><a class="reference internal" href="#rmm">8.1.2.6.2.1. RMM</a></li>
<li><a class="reference internal" href="#id1">8.1.2.6.2.2. CuPy</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="integer-typing.html" title="Previous Chapter: 8.1.1. NBEP 1: Changes in integer typing"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; 8.1.1. NBEP 1...</span>
    </a>
  </li>
  <li>
    <a href="extension-points.html" title="Next Chapter: 8.2.1. NBEP 2: Extension points"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">8.2.1. NBEP 2... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/proposals/external-memory-management.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="nbep-7-cuda-external-memory-management-plugins">
<span id="nbep-7"></span><h1>8.1.2. NBEP 7: CUDA External Memory Management Plugins<a class="headerlink" href="#nbep-7-cuda-external-memory-management-plugins" title="Permalink to this headline">¶</a></h1>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Author:</th><td class="field-body">Graham Markall, NVIDIA</td>
</tr>
<tr class="field-even field"><th class="field-name">Contributors:</th><td class="field-body">Thomson Comer, Peter Entschev, Leo Fang, John Kirkham, Keith Kraus</td>
</tr>
<tr class="field-odd field"><th class="field-name">Date:</th><td class="field-body">March 2020</td>
</tr>
<tr class="field-even field"><th class="field-name">Status:</th><td class="field-body">Final</td>
</tr>
</tbody>
</table>
<div class="section" id="background-and-goals">
<h2>8.1.2.1. Background and goals<a class="headerlink" href="#background-and-goals" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference internal" href="../cuda/cuda_array_interface.html#cuda-array-interface"><span class="std std-ref">CUDA Array Interface</span></a> enables sharing of data
between different Python libraries that access CUDA devices. However, each
library manages its own memory distinctly from the others. For example:</p>
<ul class="simple">
<li><a class="reference external" href="https://numba.pydata.org/">Numba</a> internally manages memory for the creation
of device and mapped host arrays.</li>
<li><a class="reference external" href="https://rapids.ai/">The RAPIDS libraries</a> (cuDF, cuML, etc.) use the <a class="reference external" href="https://github.com/rapidsai/rmm">Rapids
Memory Manager</a> for allocating device
memory.</li>
<li><a class="reference external" href="https://cupy.chainer.org/">CuPy</a> includes a <a class="reference external" href="https://docs-cupy.chainer.org/en/stable/reference/memory.html">memory pool
implementation</a>
for both device and pinned memory.</li>
</ul>
<p>The goal of this NBEP is to describe a plugin interface that enables Numba’s
internal memory management to be replaced with an external memory manager by the
user. When the plugin interface is in use, Numba no longer directly allocates or
frees any memory when creating arrays, but instead requests allocations and
frees through the external manager.</p>
</div>
<div class="section" id="requirements">
<h2>8.1.2.2. Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline">¶</a></h2>
<p>Provide an <em>External Memory Manager (EMM)</em> interface in Numba.</p>
<ul class="simple">
<li>When the EMM is in use, Numba will make all memory allocation using the EMM.
It will never directly call functions such as <code class="docutils literal notranslate"><span class="pre">CuMemAlloc</span></code>, <code class="docutils literal notranslate"><span class="pre">cuMemFree</span></code>, etc.</li>
<li>When not using an <em>External Memory Manager (EMM)</em>, Numba’s present behaviour
is unchanged (at the time of writing, the current version is the 0.48
release).</li>
</ul>
<p>If an EMM is to be used, it will entirely replace Numba’s internal memory
management for the duration of program execution. An interface for setting the
memory manager will be provided.</p>
<div class="section" id="device-vs-host-memory">
<h3>8.1.2.2.1. Device vs. Host memory<a class="headerlink" href="#device-vs-host-memory" title="Permalink to this headline">¶</a></h3>
<p>An EMM will always take responsibility for the management of device memory.
However, not all CUDA memory management libraries also support managing host
memory, so a facility for Numba to continue the management of host memory
whilst ceding control of device memory to the EMM will be provided.</p>
</div>
<div class="section" id="deallocation-strategies">
<h3>8.1.2.2.2. Deallocation strategies<a class="headerlink" href="#deallocation-strategies" title="Permalink to this headline">¶</a></h3>
<p>Numba’s internal memory management uses a <a class="reference internal" href="../cuda/memory.html#deallocation-behavior"><span class="std std-ref">deallocation strategy</span></a> designed to increase efficiency by deferring
deallocations until a significant quantity are pending. It also provides a
mechanism for preventing deallocations entirely during critical sections, using
the <a class="reference internal" href="../cuda/memory.html#numba.cuda.defer_cleanup" title="numba.cuda.defer_cleanup"><code class="xref py py-func docutils literal notranslate"><span class="pre">defer_cleanup()</span></code></a> context manager.</p>
<ul class="simple">
<li>When the EMM is not in use, the deallocation strategy and operation of
<code class="docutils literal notranslate"><span class="pre">defer_cleanup</span></code> remain unchanged.</li>
<li>When the EMM is in use, the deallocation strategy is implemented by the EMM,
and Numba’s internal deallocation mechanism is not used. For example:<ul>
<li>A similar strategy to Numba’s could be implemented by the EMM, or</li>
<li>Deallocated memory might immediately be returned to a memory pool.</li>
</ul>
</li>
<li>The <code class="docutils literal notranslate"><span class="pre">defer_cleanup</span></code> context manager may behave differently with an EMM - an
EMM should be accompanied by documentation of the behaviour of the
<code class="docutils literal notranslate"><span class="pre">defer_cleanup</span></code> context manager when it is in use.<ul>
<li>For example, a pool allocator could always immediately return memory to a
pool even when the context manager is in use, but could choose
not to free empty pools until <code class="docutils literal notranslate"><span class="pre">defer_cleanup</span></code> is not in use.</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="management-of-other-objects">
<h3>8.1.2.2.3. Management of other objects<a class="headerlink" href="#management-of-other-objects" title="Permalink to this headline">¶</a></h3>
<p>In addition to memory, Numba manages the allocation and deallocation of
<a class="reference internal" href="../cuda-reference/host.html#events"><span class="std std-ref">events</span></a>, <a class="reference internal" href="../cuda-reference/host.html#streams"><span class="std std-ref">streams</span></a>, and modules (a module is a
compiled object, which is generated from <code class="docutils literal notranslate"><span class="pre">&#64;cuda.jit</span></code>-ted functions). The
management of streams, events, and modules should be unchanged by the presence
or absence of an EMM.</p>
</div>
<div class="section" id="asynchronous-allocation-deallocation">
<h3>8.1.2.2.4. Asynchronous allocation / deallocation<a class="headerlink" href="#asynchronous-allocation-deallocation" title="Permalink to this headline">¶</a></h3>
<p>An asynchronous memory manager might provide the facility for an allocation or
free to take a CUDA stream and execute asynchronously. For freeing, this is
unlikely to cause issues since it operates at a layer beneath Python, but for
allocations this could be problematic if the user tries to then launch a kernel
on the default stream from this asynchronous memory allocation.</p>
<p>The interface described in this proposal will not be required to support
asynchronous allocation and deallocation, and as such these use cases will not
be considered further. However, nothing in this proposal should preclude the
straightforward addition of asynchronous operations in future versions of the
interface.</p>
</div>
<div class="section" id="non-requirements">
<h3>8.1.2.2.5. Non-requirements<a class="headerlink" href="#non-requirements" title="Permalink to this headline">¶</a></h3>
<p>In order to minimise complexity and constrain this proposal to a reasonable
scope, the following will not be supported:</p>
<ul class="simple">
<li>Using different memory manager implementations for different contexts. All
contexts will use the same memory manager implementation - either the Numba
internal implementation or an external implementation.</li>
<li>Changing the memory manager once execution has begun. It is not practical to
change the memory manager and retain all allocations. Cleaning up the entire
state and then changing to a different memory allocator (rather than starting
a new process) appears to be a rather niche use case.</li>
<li>Any changes to the <code class="docutils literal notranslate"><span class="pre">__cuda_array_interface__</span></code> to further define its semantics,
e.g. for acquiring / releasing memory as discussed in <a class="reference external" href="https://github.com/numba/numba/issues/4886">Numba Issue
#4886</a> - these are independent,
and can be addressed as part of separate proposals.</li>
<li>Managed memory / UVM is not supported. At present Numba does not support UVM -
see <a class="reference external" href="https://github.com/numba/numba/issues/4362">Numba Issue #4362</a> for
discussion of support.</li>
</ul>
</div>
</div>
<div class="section" id="interface-for-plugin-developers">
<h2>8.1.2.3. Interface for Plugin developers<a class="headerlink" href="#interface-for-plugin-developers" title="Permalink to this headline">¶</a></h2>
<p>New classes and functions will be added to <code class="docutils literal notranslate"><span class="pre">numba.cuda.cudadrv.driver</span></code>:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">BaseCUDAMemoryManager</span></code> and <code class="docutils literal notranslate"><span class="pre">HostOnlyCUDAMemoryManager</span></code>: base classes for
EMM plugin implementations.</li>
<li><code class="docutils literal notranslate"><span class="pre">set_memory_manager</span></code>: a method for registering an external memory manager with
Numba.</li>
</ul>
<p>These will be exposed through the public API, in the <code class="docutils literal notranslate"><span class="pre">numba.cuda</span></code> module.
Additionally, some classes that are already part of the <cite>driver</cite> module will be
exposed as part of the public API:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">MemoryPointer</span></code>: used to encapsulate information about a pointer to device
memory.</li>
<li><code class="docutils literal notranslate"><span class="pre">MappedMemory</span></code>: used to hold information about host memory that is mapped into
the device address space (a subclass of <code class="docutils literal notranslate"><span class="pre">MemoryPointer</span></code>).</li>
<li><code class="docutils literal notranslate"><span class="pre">PinnedMemory</span></code>: used to hold information about host memory that is pinned (a
subclass of <code class="docutils literal notranslate"><span class="pre">mviewbuf.MemAlloc</span></code>, a class internal to Numba).</li>
</ul>
<p>As an alternative to calling the <code class="docutils literal notranslate"><span class="pre">set_memory_manager</span></code> function, an environment
variable can be used to set the memory manager. The value of the environment
variable should be the name of the module containing the memory manager in its
global scope, named <code class="docutils literal notranslate"><span class="pre">_numba_memory_manager</span></code>:</p>
<p>When this variable is set, Numba will automatically use the memory manager from
the specified module. Calls to <code class="docutils literal notranslate"><span class="pre">set_memory_manager</span></code> will issue a warning, but
otherwise be ignored.</p>
<div class="section" id="plugin-base-classes">
<h3>8.1.2.3.1. Plugin Base Classes<a class="headerlink" href="#plugin-base-classes" title="Permalink to this headline">¶</a></h3>
<p>An EMM plugin is implemented by inheriting from the <code class="docutils literal notranslate"><span class="pre">BaseCUDAMemoryManager</span></code>
class, which is defined as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BaseCUDAMemoryManager</span><span class="p">(</span><span class="nb">object</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">memalloc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Allocate on-device memory in the current context. Arguments:</span>

<span class="sd">        - `size`: Size of allocation in bytes</span>

<span class="sd">        Returns: a `MemoryPointer` to the allocated memory.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">memhostalloc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">mapped</span><span class="p">,</span> <span class="n">portable</span><span class="p">,</span> <span class="n">wc</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Allocate pinned host memory. Arguments:</span>

<span class="sd">        - `size`: Size of the allocation in bytes</span>
<span class="sd">        - `mapped`: Whether the allocated memory should be mapped into the CUDA</span>
<span class="sd">                    address space.</span>
<span class="sd">        - `portable`: Whether the memory will be considered pinned by all</span>
<span class="sd">                      contexts, and not just the calling context.</span>
<span class="sd">        - `wc`: Whether to allocate the memory as write-combined.</span>

<span class="sd">        Returns a `MappedMemory` or `PinnedMemory` instance that owns the</span>
<span class="sd">        allocated memory, depending on whether the region was mapped into</span>
<span class="sd">        device memory.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">mempin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">owner</span><span class="p">,</span> <span class="n">pointer</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">mapped</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Pin a region of host memory that is already allocated. Arguments:</span>

<span class="sd">        - `owner`: An object owning the memory - e.g. a `DeviceNDArray`.</span>
<span class="sd">        - `pointer`: The pointer to the beginning of the region to pin.</span>
<span class="sd">        - `size`: The size of the region to pin.</span>
<span class="sd">        - `mapped`: Whether the region should also be mapped into device memory.</span>

<span class="sd">        Returns a `MappedMemory` or `PinnedMemory` instance that refers to the</span>
<span class="sd">        allocated memory, depending on whether the region was mapped into device</span>
<span class="sd">        memory.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform any initialization required for the EMM plugin to be ready to</span>
<span class="sd">        use.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">get_memory_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns (free, total) memory in bytes in the context</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">get_ipc_handle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memory</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return an `IpcHandle` from a GPU allocation. Arguments:</span>

<span class="sd">        - `memory`: A `MemoryPointer` for which the IPC handle should be created.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Clear up all memory allocated in this context.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">defer_cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns a context manager that ensures the implementation of deferred</span>
<span class="sd">        cleanup whilst it is active.</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">interface_version</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns an integer specifying the version of the EMM Plugin interface</span>
<span class="sd">        supported by the plugin implementation. Should always return 1 for</span>
<span class="sd">        implementations described in this proposal.</span>
<span class="sd">        &quot;&quot;&quot;</span>
</pre></div>
</div>
<p>All of the methods of an EMM plugin are called from within Numba - they never
need to be invoked directly by a Numba user.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">initialize</span></code> method is called by Numba prior to any memory allocations
being requested. This gives the EMM an opportunity to initialize any data
structures, etc., that it needs for its normal operations. The method may be
called multiple times during the lifetime of the program - subsequent calls
should not invalidate or reset the state of the EMM.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">memalloc</span></code>, <code class="docutils literal notranslate"><span class="pre">memhostalloc</span></code>, and <code class="docutils literal notranslate"><span class="pre">mempin</span></code> methods are called when Numba
requires an allocation of device or host memory, or pinning of host memory.
Device memory should always be allocated in the current context.</p>
<p><code class="docutils literal notranslate"><span class="pre">get_ipc_handle</span></code> is called when an IPC handle for an array is required. Note
that there is no method for closing an IPC handle - this is because the
<code class="docutils literal notranslate"><span class="pre">IpcHandle</span></code> object constructed by <code class="docutils literal notranslate"><span class="pre">get_ipc_handle</span></code> contains a <code class="docutils literal notranslate"><span class="pre">close()</span></code> method
as part of its definition in Numba, which closes the handle by calling
<code class="docutils literal notranslate"><span class="pre">cuIpcCloseMemHandle</span></code>. It is expected that this is sufficient for general use
cases, so no facility for customising the closing of IPC handles is provided by
the EMM Plugin interface.</p>
<p><code class="docutils literal notranslate"><span class="pre">get_memory_info</span></code> may be called at any time after <code class="docutils literal notranslate"><span class="pre">initialize</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">reset</span></code> is called as part of resetting a context. Numba does not normally call
reset spontaneously, but it may be called at the behest of the user. Calls to
<code class="docutils literal notranslate"><span class="pre">reset</span></code> may even occur before <code class="docutils literal notranslate"><span class="pre">initialize</span></code> is called, so the plugin should be
robust against this occurrence.</p>
<p><code class="docutils literal notranslate"><span class="pre">defer_cleanup</span></code> is called when the <code class="docutils literal notranslate"><span class="pre">numba.cuda.defer_cleanup</span></code> context manager
is used from user code.</p>
<p><code class="docutils literal notranslate"><span class="pre">interface_version</span></code> is called by Numba when the memory manager is set, to
ensure that the version of the interface implemented by the plugin is
compatible with the version of Numba in use.</p>
</div>
<div class="section" id="representing-pointers">
<h3>8.1.2.3.2. Representing pointers<a class="headerlink" href="#representing-pointers" title="Permalink to this headline">¶</a></h3>
<div class="section" id="device-memory">
<h4>8.1.2.3.2.1. Device Memory<a class="headerlink" href="#device-memory" title="Permalink to this headline">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">MemoryPointer</span></code> class is used to represent a pointer to memory. Whilst there
are various details of its implementation, the only aspect relevant to EMM
plugin development is its initialization. The <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method has the
following interface:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MemoryPointer</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">pointer</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">owner</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">finalizer</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
</pre></div>
</div>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">context</span></code>: The context in which the pointer was allocated.</li>
<li><code class="docutils literal notranslate"><span class="pre">pointer</span></code>: A <code class="docutils literal notranslate"><span class="pre">ctypes</span></code> pointer (e.g. <code class="docutils literal notranslate"><span class="pre">ctypes.c_uint64</span></code>) holding the address of
the memory.</li>
<li><code class="docutils literal notranslate"><span class="pre">size</span></code>: The size of the allocation in bytes.</li>
<li><code class="docutils literal notranslate"><span class="pre">owner</span></code>: The owner is sometimes set by the internals of the class, or used for
Numba’s internal memory management, but need not be provided by the writer of
an EMM plugin - the default of <code class="docutils literal notranslate"><span class="pre">None</span></code> should always suffice.</li>
<li><code class="docutils literal notranslate"><span class="pre">finalizer</span></code>: A method that is called when the last reference to the
<code class="docutils literal notranslate"><span class="pre">MemoryPointer</span></code> object is released. Usually this will make a call to the
external memory management library to inform it that the memory is no longer
required, and that it could potentially be freed (though the EMM is not
required to free it immediately).</li>
</ul>
</div>
<div class="section" id="host-memory">
<h4>8.1.2.3.2.2. Host Memory<a class="headerlink" href="#host-memory" title="Permalink to this headline">¶</a></h4>
<p>Memory mapped into the CUDA address space (which is created when the
<code class="docutils literal notranslate"><span class="pre">memhostalloc</span></code> or <code class="docutils literal notranslate"><span class="pre">mempin</span></code> methods are called with <code class="docutils literal notranslate"><span class="pre">mapped=True</span></code>) is managed
using the <code class="docutils literal notranslate"><span class="pre">MappedMemory</span></code> class:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MappedMemory</span><span class="p">(</span><span class="n">AutoFreePointer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">pointer</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">owner</span><span class="p">,</span> <span class="n">finalizer</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
</pre></div>
</div>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">context</span></code>: The context in which the pointer was allocated.</li>
<li><code class="docutils literal notranslate"><span class="pre">pointer</span></code>: A <code class="docutils literal notranslate"><span class="pre">ctypes</span></code> pointer (e.g. <code class="docutils literal notranslate"><span class="pre">ctypes.c_void_p</span></code>) holding the address of
the allocated memory.</li>
<li><code class="docutils literal notranslate"><span class="pre">size</span></code>: The size of the allocated memory in bytes.</li>
<li><code class="docutils literal notranslate"><span class="pre">owner</span></code>: A Python object that owns the memory, e.g. a <code class="docutils literal notranslate"><span class="pre">DeviceNDArray</span></code>
instance.</li>
<li><code class="docutils literal notranslate"><span class="pre">finalizer</span></code>: A method that is called when the last reference to the
<code class="docutils literal notranslate"><span class="pre">MappedMemory</span></code> object is released. For example, this method could call
<code class="docutils literal notranslate"><span class="pre">cuMemFreeHost</span></code> on the pointer to deallocate the memory immediately.</li>
</ul>
<p>Note that the inheritance from <code class="docutils literal notranslate"><span class="pre">AutoFreePointer</span></code> is an implementation detail and
need not concern the developer of an EMM plugin - <code class="docutils literal notranslate"><span class="pre">MemoryPointer</span></code> is higher in
the MRO of <code class="docutils literal notranslate"><span class="pre">MappedMemory</span></code>.</p>
<p>Memory that is only in the host address space and has been pinned is represented
with the <code class="docutils literal notranslate"><span class="pre">PinnedMemory</span></code> class:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">PinnedMemory</span><span class="p">(</span><span class="n">mviewbuf</span><span class="o">.</span><span class="n">MemAlloc</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">pointer</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">owner</span><span class="p">,</span> <span class="n">finalizer</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
</pre></div>
</div>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">context</span></code>: The context in which the pointer was allocated.</li>
<li><code class="docutils literal notranslate"><span class="pre">pointer</span></code>: A <code class="docutils literal notranslate"><span class="pre">ctypes</span></code> pointer (e.g. <code class="docutils literal notranslate"><span class="pre">ctypes.c_void_p</span></code>) holding the address of
the pinned memory.</li>
<li><code class="docutils literal notranslate"><span class="pre">size</span></code>: The size of the pinned region in bytes.</li>
<li><code class="docutils literal notranslate"><span class="pre">owner</span></code>: A Python object that owns the memory, e.g. a <code class="docutils literal notranslate"><span class="pre">DeviceNDArray</span></code>
instance.</li>
<li><code class="docutils literal notranslate"><span class="pre">finalizer</span></code>: A method that is called when the last reference to the
<code class="docutils literal notranslate"><span class="pre">PinnedMemory</span></code> object is released. This method could e.g. call
<code class="docutils literal notranslate"><span class="pre">cuMemHostUnregister</span></code> on the pointer to unpin the memory immediately.</li>
</ul>
</div>
</div>
<div class="section" id="providing-device-memory-management-only">
<h3>8.1.2.3.3. Providing device memory management only<a class="headerlink" href="#providing-device-memory-management-only" title="Permalink to this headline">¶</a></h3>
<p>Some external memory managers will support management of on-device memory but
not host memory. To make it easy to implement an EMM plugin using one of these
managers, Numba will provide a memory manager class with implementations of the
<code class="docutils literal notranslate"><span class="pre">memhostalloc</span></code> and <code class="docutils literal notranslate"><span class="pre">mempin</span></code> methods. An abridged definition of this class
follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">HostOnlyCUDAMemoryManager</span><span class="p">(</span><span class="n">BaseCUDAMemoryManager</span><span class="p">):</span>
    <span class="c1"># Unimplemented methods:</span>
    <span class="c1">#</span>
    <span class="c1"># - memalloc</span>
    <span class="c1"># - get_memory_info</span>

    <span class="k">def</span> <span class="nf">memhostalloc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">mapped</span><span class="p">,</span> <span class="n">portable</span><span class="p">,</span> <span class="n">wc</span><span class="p">):</span>
        <span class="c1"># Implemented.</span>

    <span class="k">def</span> <span class="nf">mempin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">owner</span><span class="p">,</span> <span class="n">pointer</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">mapped</span><span class="p">):</span>
        <span class="c1"># Implemented.</span>

    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Implemented.</span>
        <span class="c1">#</span>
        <span class="c1"># Must be called by any subclass when its initialize() method is</span>
        <span class="c1"># called.</span>

    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Implemented.</span>
        <span class="c1">#</span>
        <span class="c1"># Must be called by any subclass when its reset() method is</span>
        <span class="c1"># called.</span>

    <span class="k">def</span> <span class="nf">defer_cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Implemented.</span>
        <span class="c1">#</span>
        <span class="c1"># Must be called by any subclass when its defer_cleanup() method is</span>
        <span class="c1"># called.</span>
</pre></div>
</div>
<p>A class can subclass the <code class="docutils literal notranslate"><span class="pre">HostOnlyCUDAMemoryManager</span></code> and then it only needs to
add implementations of methods for on-device memory. Any subclass must observe
the following rules:</p>
<ul class="simple">
<li>If the subclass implements <code class="docutils literal notranslate"><span class="pre">__init__</span></code>, then it must also call
<code class="docutils literal notranslate"><span class="pre">HostOnlyCUDAMemoryManager.__init__</span></code>, as this is used to initialize some of
its data structures (<code class="docutils literal notranslate"><span class="pre">self.allocations</span></code> and <code class="docutils literal notranslate"><span class="pre">self.deallocations</span></code>).</li>
<li>The subclass must implement <code class="docutils literal notranslate"><span class="pre">memalloc</span></code> and <code class="docutils literal notranslate"><span class="pre">get_memory_info</span></code>.</li>
<li>The <code class="docutils literal notranslate"><span class="pre">initialize</span></code> and <code class="docutils literal notranslate"><span class="pre">reset</span></code> methods perform initialisation of structures
used by the <code class="docutils literal notranslate"><span class="pre">HostOnlyCUDAMemoryManager</span></code>.<ul>
<li>If the subclass has nothing to do on initialisation (possibly) or reset
(unlikely) then it need not implement these methods.</li>
<li>However, if it does implement these methods then it must also call the
methods from <code class="docutils literal notranslate"><span class="pre">HostOnlyCUDAMemoryManager</span></code> in its own implementations.</li>
</ul>
</li>
<li>Similarly if <code class="docutils literal notranslate"><span class="pre">defer_cleanup</span></code> is implemented, it should enter the context
provided by <code class="docutils literal notranslate"><span class="pre">HostOnlyCUDAManager.defer_cleanup()</span></code> prior to <code class="docutils literal notranslate"><span class="pre">yield</span></code>ing (or in
the <code class="docutils literal notranslate"><span class="pre">__enter__</span></code> method) and release it prior to exiting (or in the <code class="docutils literal notranslate"><span class="pre">__exit__</span></code>
method).</li>
</ul>
</div>
<div class="section" id="import-order">
<h3>8.1.2.3.4. Import order<a class="headerlink" href="#import-order" title="Permalink to this headline">¶</a></h3>
<p>The order in which Numba and the library implementing an EMM Plugin should not
matter. For example, if <code class="docutils literal notranslate"><span class="pre">rmm</span></code> were to implement and register an EMM Plugin,
then:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">cuda</span>
<span class="kn">import</span> <span class="nn">rmm</span>
</pre></div>
</div>
<p>and</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">rmm</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">cuda</span>
</pre></div>
</div>
<p>are equivalent - this is because Numba does not initialize CUDA or allocate any
memory until the first call to a CUDA function - neither instantiating and
registering an EMM plugin, nor importing <code class="docutils literal notranslate"><span class="pre">numba.cuda</span></code> causes a call to a CUDA
function.</p>
</div>
<div class="section" id="numba-as-a-dependency">
<h3>8.1.2.3.5. Numba as a Dependency<a class="headerlink" href="#numba-as-a-dependency" title="Permalink to this headline">¶</a></h3>
<p>Adding the implementation of an EMM Plugin to a library naturally makes Numba a
dependency of the library where it may not have been previously. In order to
make the dependency optional, if this is desired, one might conditionally
instantiate and register the EMM Plugin like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">numba</span>
    <span class="kn">from</span> <span class="nn">mylib.numba_utils</span> <span class="kn">import</span> <span class="n">MyNumbaMemoryManager</span>
    <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">cudadrv</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">set_memory_manager</span><span class="p">(</span><span class="n">MyNumbaMemoryManager</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Numba not importable - not registering EMM Plugin&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>so that <code class="docutils literal notranslate"><span class="pre">mylib.numba_utils</span></code>, which contains the implementation of the EMM
Plugin, is only imported if Numba is already present. If Numba is not available,
then <code class="docutils literal notranslate"><span class="pre">mylib.numba_utils</span></code> (which necessarily imports <code class="docutils literal notranslate"><span class="pre">numba</span></code>), will never be
imported.</p>
<p>It is recommended that any library with an EMM Plugin includes at least some
environments with Numba for testing with the EMM Plugin in use, as well as some
environments without Numba, to avoid introducing an accidental Numba dependency.</p>
</div>
</div>
<div class="section" id="example-implementation-a-rapids-memory-manager-rmm-plugin">
<h2>8.1.2.4. Example implementation - A RAPIDS Memory Manager (RMM) Plugin<a class="headerlink" href="#example-implementation-a-rapids-memory-manager-rmm-plugin" title="Permalink to this headline">¶</a></h2>
<p>An implementation of an EMM plugin within the <a class="reference external" href="https://github.com/rapidsai/rmm">Rapids Memory Manager
(RMM)</a> is sketched out in this section. This is
intended to show an overview of the implementation in order to support the
descriptions above and to illustrate how the plugin interface can be used -
different choices may be made for a production-ready implementation.</p>
<p>The plugin implementation consists of additions to <a class="reference external" href="https://github.com/rapidsai/rmm/blob/d5831ac5ebb5408ee83f63b7c7d03d8870ecb361/python/rmm/rmm.py">python/rmm/rmm.py</a>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># New imports:</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">context_manager</span>
<span class="c1"># RMM already has Numba as a dependency, so these imports need not be guarded</span>
<span class="c1"># by a check for the presence of numba.</span>
<span class="kn">from</span> <span class="nn">numba.cuda</span> <span class="kn">import</span> <span class="p">(</span><span class="n">HostOnlyCUDAMemoryManager</span><span class="p">,</span> <span class="n">MemoryPointer</span><span class="p">,</span> <span class="n">IpcHandle</span><span class="p">,</span>
                        <span class="n">set_memory_manager</span><span class="p">)</span>


<span class="c1"># New class implementing the EMM Plugin:</span>
<span class="k">class</span> <span class="nc">RMMNumbaManager</span><span class="p">(</span><span class="n">HostOnlyCUDAMemoryManager</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">memalloc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="c1"># Allocates device memory using RMM functions. The finalizer for the</span>
        <span class="c1"># allocated memory calls back to RMM to free the memory.</span>
        <span class="n">addr</span> <span class="o">=</span> <span class="n">librmm</span><span class="o">.</span><span class="n">rmm_alloc</span><span class="p">(</span><span class="n">bytesize</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">ctx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">current_context</span><span class="p">()</span>
        <span class="n">ptr</span> <span class="o">=</span> <span class="n">ctypes</span><span class="o">.</span><span class="n">c_uint64</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">addr</span><span class="p">))</span>
        <span class="n">finalizer</span> <span class="o">=</span> <span class="n">_make_finalizer</span><span class="p">(</span><span class="n">addr</span><span class="p">,</span> <span class="n">stream</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">MemoryPointer</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">ptr</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">finalizer</span><span class="o">=</span><span class="n">finalizer</span><span class="p">)</span>

   <span class="k">def</span> <span class="nf">get_ipc_handle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memory</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get an IPC handle for the memory with offset modified by the RMM memory</span>
<span class="sd">        pool.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># This implementation provides a functional implementation and illustrates</span>
        <span class="c1"># what get_ipc_handle needs to do, but it is not a very &quot;clean&quot;</span>
        <span class="c1"># implementation, and it relies on borrowing bits of Numba internals to</span>
        <span class="c1"># initialise ipchandle.</span>
        <span class="c1">#</span>
        <span class="c1"># A more polished implementation might make use of additional functions in</span>
        <span class="c1"># the RMM C++ layer for initialising IPC handles, and not use any Numba</span>
        <span class="c1"># internals.</span>
        <span class="n">ipchandle</span> <span class="o">=</span> <span class="p">(</span><span class="n">ctypes</span><span class="o">.</span><span class="n">c_byte</span> <span class="o">*</span> <span class="mi">64</span><span class="p">)()</span>  <span class="c1"># IPC handle is 64 bytes</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">cudadrv</span><span class="o">.</span><span class="n">memory</span><span class="o">.</span><span class="n">driver_funcs</span><span class="o">.</span><span class="n">cuIpcGetMemHandle</span><span class="p">(</span>
            <span class="n">ctypes</span><span class="o">.</span><span class="n">byref</span><span class="p">(</span><span class="n">ipchandle</span><span class="p">),</span>
            <span class="n">memory</span><span class="o">.</span><span class="n">owner</span><span class="o">.</span><span class="n">handle</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">source_info</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">current_context</span><span class="p">()</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">get_device_identity</span><span class="p">()</span>
        <span class="n">ptr</span> <span class="o">=</span> <span class="n">memory</span><span class="o">.</span><span class="n">device_ctypes_pointer</span><span class="o">.</span><span class="n">value</span>
        <span class="n">offset</span> <span class="o">=</span> <span class="n">librmm</span><span class="o">.</span><span class="n">rmm_getallocationoffset</span><span class="p">(</span><span class="n">ptr</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">IpcHandle</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">ipchandle</span><span class="p">,</span> <span class="n">memory</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">source_info</span><span class="p">,</span>
                         <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_memory_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Returns a tuple of (free, total) using RMM functionality.</span>
        <span class="k">return</span> <span class="n">get_info</span><span class="p">()</span> <span class="c1"># Function defined in rmm.py</span>

    <span class="k">def</span> <span class="nf">initialize</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Nothing required to initialize RMM here, but this method is added</span>
        <span class="c1"># to illustrate that the super() method should also be called.</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>

    <span class="nd">@contextmanager</span>
    <span class="k">def</span> <span class="nf">defer_cleanup</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># Does nothing to defer cleanup - a full implementation may choose to</span>
        <span class="c1"># implement a different policy.</span>
        <span class="k">with</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">defer_cleanup</span><span class="p">():</span>
            <span class="k">yield</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">interface_version</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># As required by the specification</span>
        <span class="k">return</span> <span class="mi">1</span>

<span class="c1"># The existing _make_finalizer function is used by RMMNumbaManager:</span>
<span class="k">def</span> <span class="nf">_make_finalizer</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">stream</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Factory to make the finalizer function.</span>
<span class="sd">    We need to bind *handle* and *stream* into the actual finalizer, which</span>
<span class="sd">    takes no args.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">finalizer</span><span class="p">():</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Invoked when the MemoryPointer is freed</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">librmm</span><span class="o">.</span><span class="n">rmm_free</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">stream</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">finalizer</span>

<span class="c1"># Utility function register `RMMNumbaManager` as an EMM:</span>
<span class="k">def</span> <span class="nf">use_rmm_for_numba</span><span class="p">():</span>
    <span class="n">set_memory_manager</span><span class="p">(</span><span class="n">RMMNumbaManager</span><span class="p">)</span>

<span class="c1"># To support `NUMBA_CUDA_MEMORY_MANAGER=rmm`:</span>
<span class="n">_numba_memory_manager</span> <span class="o">=</span> <span class="n">RMMNumbaManager</span>
</pre></div>
</div>
<div class="section" id="example-usage">
<h3>8.1.2.4.1. Example usage<a class="headerlink" href="#example-usage" title="Permalink to this headline">¶</a></h3>
<p>A simple example that configures Numba to use RMM for memory management and
creates a device array is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># example.py</span>
<span class="kn">import</span> <span class="nn">rmm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">cuda</span>

<span class="n">rmm</span><span class="o">.</span><span class="n">use_rmm_for_numba</span><span class="p">()</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">d_a</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">del</span><span class="p">(</span><span class="n">d_a</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">rmm</span><span class="o">.</span><span class="n">csv_log</span><span class="p">())</span>
</pre></div>
</div>
<p>Running this should result in output similar to the following:</p>
<p>Note that there is some scope for improvement in RMM for detecting the line
number at which the allocation / free occurred, but this is outside the scope of
the example in this proposal.</p>
<div class="section" id="setting-the-memory-manager-through-the-environment">
<h4>8.1.2.4.1.1. Setting the memory manager through the environment<a class="headerlink" href="#setting-the-memory-manager-through-the-environment" title="Permalink to this headline">¶</a></h4>
<p>Rather than calling <code class="docutils literal notranslate"><span class="pre">rmm.use_rmm_for_numba()</span></code> in the example above, the memory
manager could also be set to use RMM globally with an environment variable, so
the Python interpreter is invoked to run the example as:</p>
</div>
</div>
</div>
<div class="section" id="numba-internal-changes">
<h2>8.1.2.5. Numba internal changes<a class="headerlink" href="#numba-internal-changes" title="Permalink to this headline">¶</a></h2>
<p>This section is intended primarily for Numba developers - those with an interest
in the external interface for implementing EMM plugins may choose to skip over
this section.</p>
<div class="section" id="current-model-implementation">
<h3>8.1.2.5.1. Current model / implementation<a class="headerlink" href="#current-model-implementation" title="Permalink to this headline">¶</a></h3>
<p>At present, memory management is implemented in the
<a class="reference internal" href="../cuda-reference/host.html#numba.cuda.cudadrv.driver.Context" title="numba.cuda.cudadrv.driver.Context"><code class="xref py py-class docutils literal notranslate"><span class="pre">Context</span></code></a> class. It maintains lists of
allocations and deallocations:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">allocations</span></code> is a <code class="docutils literal notranslate"><span class="pre">numba.core.utils.UniqueDict</span></code>, created at context
creation time.</li>
<li><code class="docutils literal notranslate"><span class="pre">deallocations</span></code> is an instance of the <code class="docutils literal notranslate"><span class="pre">_PendingDeallocs</span></code> class, and is created
when <code class="docutils literal notranslate"><span class="pre">Context.prepare_for_use()</span></code> is called.</li>
</ul>
<p>These are used to track allocations and deallocations of:</p>
<ul class="simple">
<li>Device memory</li>
<li>Pinned memory</li>
<li>Mapped memory</li>
<li>Streams</li>
<li>Events</li>
<li>Modules</li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">_PendingDeallocs</span></code> class implements the deferred deallocation strategy -
cleanup functions (such as <code class="docutils literal notranslate"><span class="pre">cuMemFree</span></code>) for the items above are added to its
list of pending deallocations by the finalizers of objects representing
allocations. These finalizers are run when the objects owning them are
garbage-collected by the Python interpreter. When the addition of a new
cleanup function to the deallocation list causes the number or size of pending
deallocations to exceed a configured ratio, the <code class="docutils literal notranslate"><span class="pre">_PendingDeallocs</span></code> object runs
deallocators for all items it knows about and then clears its internal pending
list.</p>
<p>See <a class="reference internal" href="../cuda/memory.html#deallocation-behavior"><span class="std std-ref">Deallocation Behavior</span></a> for more details of this implementation.</p>
</div>
<div class="section" id="proposed-changes">
<h3>8.1.2.5.2. Proposed changes<a class="headerlink" href="#proposed-changes" title="Permalink to this headline">¶</a></h3>
<p>This section outlines the major changes that will be made to support the EMM
plugin interface - there will be various small changes to other parts of Numba
that will be required in order to adapt to these changes; an exhaustive list of
these is not provided.</p>
<div class="section" id="context-changes">
<h4>8.1.2.5.2.1. Context changes<a class="headerlink" href="#context-changes" title="Permalink to this headline">¶</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">numba.cuda.cudadrv.driver.Context</span></code> class will no longer directly allocate
and free memory. Instead, the context will hold a reference to a memory manager
instance, and its memory allocation methods will call into the memory manager,
e.g.:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">memalloc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory_manager</span><span class="o">.</span><span class="n">memalloc</span><span class="p">(</span><span class="n">size</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">memhostalloc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">mapped</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">portable</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">wc</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory_manager</span><span class="o">.</span><span class="n">memhostalloc</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">mapped</span><span class="p">,</span> <span class="n">portable</span><span class="p">,</span> <span class="n">wc</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">mempin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">owner</span><span class="p">,</span> <span class="n">pointer</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">mapped</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">mapped</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">CAN_MAP_HOST_MEMORY</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">CudaDriverError</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> cannot map host memory&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory_manager</span><span class="o">.</span><span class="n">mempin</span><span class="p">(</span><span class="n">owner</span><span class="p">,</span> <span class="n">pointer</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">mapped</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">prepare_for_use</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">memory_manager</span><span class="o">.</span><span class="n">initialize</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">get_memory_info</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">memory_manager</span><span class="o">.</span><span class="n">get_memory_info</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">get_ipc_handle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memory</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory_manager</span><span class="o">.</span><span class="n">get_ipc_handle</span><span class="p">(</span><span class="n">memory</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># ... Already-extant reset logic, plus:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_memory_manager</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">memory_manager</span></code> member is initialised when the context is created.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">memunpin</span></code> method (not shown above but currently exists in the <code class="docutils literal notranslate"><span class="pre">Context</span></code>
class) has never been implemented - it presently raises a <code class="docutils literal notranslate"><span class="pre">NotImplementedError</span></code>.
This method arguably un-needed - pinned memory is immediately unpinned by its
finalizer, and unpinning before a finalizer runs would invalidate the state of
<code class="docutils literal notranslate"><span class="pre">PinnedMemory</span></code> objects for which references are still held. It is proposed that
this is removed when making the other changes to the <code class="docutils literal notranslate"><span class="pre">Context</span></code> class.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">Context</span></code> class will still instantiate <code class="docutils literal notranslate"><span class="pre">self.allocations</span></code> and
<code class="docutils literal notranslate"><span class="pre">self.deallocations</span></code> as before - these will still be used by the context to
manage the allocations and deallocations of events, streams, and modules, which
are not handled by the EMM plugin.</p>
</div>
<div class="section" id="new-components-of-the-driver-module">
<h4>8.1.2.5.2.2. New components of the <code class="docutils literal notranslate"><span class="pre">driver</span></code> module<a class="headerlink" href="#new-components-of-the-driver-module" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">BaseCUDAMemoryManager</span></code>: An abstract class, as defined in the plugin interface
above.</li>
<li><code class="docutils literal notranslate"><span class="pre">HostOnlyCUDAMemoryManager</span></code>: A subclass of <code class="docutils literal notranslate"><span class="pre">BaseCUDAMemoryManager</span></code>, with the
logic from <code class="docutils literal notranslate"><span class="pre">Context.memhostalloc</span></code> and <code class="docutils literal notranslate"><span class="pre">Context.mempin</span></code> moved into it. This
class will also create its own <code class="docutils literal notranslate"><span class="pre">allocations</span></code> and <code class="docutils literal notranslate"><span class="pre">deallocations</span></code> members,
similarly to how the <code class="docutils literal notranslate"><span class="pre">Context</span></code> class creates them. These are used to manage
the allocations and deallocations of pinned and mapped host memory.</li>
<li><code class="docutils literal notranslate"><span class="pre">NumbaCUDAMemoryManager</span></code>: A subclass of <code class="docutils literal notranslate"><span class="pre">HostOnlyCUDAMemoryManager</span></code>, which
also contains an implementation of <code class="docutils literal notranslate"><span class="pre">memalloc</span></code> based on that presently existing
in the <code class="docutils literal notranslate"><span class="pre">Context</span></code> class. This is the default memory manager, and its use
preserves the behaviour of Numba prior to the addition of the EMM plugin
interface - that is, all memory allocation and deallocation for Numba arrays
is handled within Numba.<ul>
<li>This class shares the <code class="docutils literal notranslate"><span class="pre">allocations</span></code> and <code class="docutils literal notranslate"><span class="pre">deallocations</span></code> members with its
parent class <code class="docutils literal notranslate"><span class="pre">HostOnlyCUDAMemoryManager</span></code>, and it uses these for the
management of device memory that it allocates.</li>
</ul>
</li>
<li>The <code class="docutils literal notranslate"><span class="pre">set_memory_manager</span></code> function, which sets a global pointing to the memory
manager class. This global initially holds <code class="docutils literal notranslate"><span class="pre">NumbaCUDAMemoryManager</span></code> (the
default).</li>
</ul>
</div>
<div class="section" id="staged-ipc">
<h4>8.1.2.5.2.3. Staged IPC<a class="headerlink" href="#staged-ipc" title="Permalink to this headline">¶</a></h4>
<p>Staged IPC should not take ownership of the memory that it allocates. When the
default internal memory manager is in use, the memory allocated for the staging
array is already owned. When an EMM plugin is in use, it is not legitimate to
take ownership of the memory.</p>
<p>This change can be made by applying the following small patch, which has been
tested to have no effect on the CUDA test suite:</p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span><span class="gh">diff --git a/numba/cuda/cudadrv/driver.py b/numba/cuda/cudadrv/driver.py</span>
<span class="gh">index 7832955..f2c1352 100644</span>
<span class="gd">--- a/numba/cuda/cudadrv/driver.py</span>
<span class="gi">+++ b/numba/cuda/cudadrv/driver.py</span>
<span class="gu">@@ -922,7 +922,11 @@ class _StagedIpcImpl(object):</span>
         with cuda.gpus[srcdev.id]:
             impl.close()

<span class="gd">-        return newmem.own()</span>
<span class="gi">+        return newmem</span>
</pre></div>
</div>
</div>
<div class="section" id="testing">
<h4>8.1.2.5.2.4. Testing<a class="headerlink" href="#testing" title="Permalink to this headline">¶</a></h4>
<p>Alongside the addition of appropriate tests for new functionality, there will be
some refactoring of existing tests required, but these changes are not
substantial. Tests of the deallocation strategy (e.g. <code class="docutils literal notranslate"><span class="pre">TestDeallocation</span></code>,
<code class="docutils literal notranslate"><span class="pre">TestDeferCleanup</span></code>) will need to be modified to ensure that they are
examining the correct set of deallocations. When an EMM plugin is in use, they
will need to be skipped.</p>
</div>
</div>
</div>
<div class="section" id="prototyping-experimental-implementation">
<h2>8.1.2.6. Prototyping / experimental implementation<a class="headerlink" href="#prototyping-experimental-implementation" title="Permalink to this headline">¶</a></h2>
<p>Some prototype / experimental implementations have been produced to guide the
designs presented in this document. The current implementations can be found in:</p>
<ul class="simple">
<li>Numba branch: <a class="reference external" href="https://github.com/gmarkall/numba/tree/grm-numba-nbep-7">https://github.com/gmarkall/numba/tree/grm-numba-nbep-7</a>.</li>
<li>RMM branch: <a class="reference external" href="https://github.com/gmarkall/rmm/tree/grm-numba-nbep-7">https://github.com/gmarkall/rmm/tree/grm-numba-nbep-7</a>.</li>
<li>CuPy implementation:
<a class="reference external" href="https://github.com/gmarkall/nbep-7/blob/master/nbep7/cupy_mempool.py">https://github.com/gmarkall/nbep-7/blob/master/nbep7/cupy_mempool.py</a> - uses
an unmodified CuPy.<ul>
<li>See <a class="reference external" href="https://docs-cupy.chainer.org/en/stable/reference/memory.html">CuPy memory management
docs</a>.</li>
</ul>
</li>
</ul>
<div class="section" id="current-implementation-status">
<h3>8.1.2.6.1. Current implementation status<a class="headerlink" href="#current-implementation-status" title="Permalink to this headline">¶</a></h3>
<div class="section" id="rmm-plugin">
<h4>8.1.2.6.1.1. RMM Plugin<a class="headerlink" href="#rmm-plugin" title="Permalink to this headline">¶</a></h4>
<p>For a minimal example, a simple allocation and free using RMM works as expected.
For the example code (similar to the RMM example above):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">rmm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">cuda</span>

<span class="n">rmm</span><span class="o">.</span><span class="n">use_rmm_for_numba</span><span class="p">()</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">d_a</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">del</span><span class="p">(</span><span class="n">d_a</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">rmm</span><span class="o">.</span><span class="n">csv_log</span><span class="p">())</span>
</pre></div>
</div>
<p>We see the following output:</p>
<p>This output is similar to the expected output from the example usage presented
above (though note that the pointer addresses and timestamps vary compared to
the example), and provides some validation of the example use case.</p>
</div>
<div class="section" id="cupy-plugin">
<h4>8.1.2.6.1.2. CuPy Plugin<a class="headerlink" href="#cupy-plugin" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nbep7.cupy_mempool</span> <span class="kn">import</span> <span class="n">use_cupy_mm_for_numba</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">cuda</span>

<span class="n">use_cupy_mm_for_numba</span><span class="p">()</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">d_a</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">del</span><span class="p">(</span><span class="n">d_a</span><span class="p">)</span>
</pre></div>
</div>
<p>The prototype CuPy plugin has somewhat primitive logging, so we see the output:</p>
</div>
</div>
<div class="section" id="numba-cuda-unit-tests">
<h3>8.1.2.6.2. Numba CUDA Unit tests<a class="headerlink" href="#numba-cuda-unit-tests" title="Permalink to this headline">¶</a></h3>
<p>As well as providing correct execution of a simple example, all relevant Numba
CUDA unit tests also pass with the prototype branch, for both the internal memory
manager and the RMM EMM Plugin.</p>
<div class="section" id="rmm">
<h4>8.1.2.6.2.1. RMM<a class="headerlink" href="#rmm" title="Permalink to this headline">¶</a></h4>
<p>The unit test suite can be run with the RMM EMM Plugin with:</p>
<p>A summary of the unit test suite output is:</p>
<p>When running with the built-in Numba memory management, the output is:</p>
<p>i.e. the changes for using an external memory manager do not break the built-in
Numba memory management. There are an additional 6 skipped tests, from:</p>
<ul class="simple">
<li><code class="docutils literal notranslate"><span class="pre">TestDeallocation</span></code>: skipped as it specifically tests Numba’s internal
deallocation strategy.</li>
<li><code class="docutils literal notranslate"><span class="pre">TestDeferCleanup</span></code>: skipped as it specifically tests Numba’s implementation of
deferred cleanup.</li>
<li><code class="docutils literal notranslate"><span class="pre">TestCudaArrayInterface.test_ownership</span></code>: skipped as Numba does not own memory
when an EMM Plugin is used, but ownership is assumed by this test case.</li>
</ul>
</div>
<div class="section" id="id1">
<h4>8.1.2.6.2.2. CuPy<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h4>
<p>The test suite can be run with the CuPy plugin using:</p>
<p>This plugin implementation is presently more primitive than the RMM
implementation, and results in some errors with the unit test suite:</p>
<p>The 8 errors are due to a lack of implementation of <code class="docutils literal notranslate"><span class="pre">get_ipc_handle</span></code> in the
CuPy EMM Plugin implementation. It is expected that this implementation will be
re-visited and completed so that CuPy can be used stably as an allocator for
Numba in the future.</p>
</div>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2012, Anaconda, Inc..<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>